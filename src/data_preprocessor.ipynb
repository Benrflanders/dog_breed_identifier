{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO:\\nUse an autoencoder to alter input rather than scaling/direct manipulation\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: clean up old methods of image processing, transfer neural network prep method into a .py script\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from skimage import io, filters, morphology, util\n",
    "\n",
    "\n",
    "from utils.general_utils import get_imgMatrix_from_id, get_random_id, get_id_from_filename, get_breed_value_from_id, populate_breeds, get_label_array_from_id, get_random_id\n",
    "\n",
    "'''\n",
    "TODO:\n",
    "Use an autoencoder to alter input rather than scaling/direct manipulation\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters to change\n",
    "np.set_printoptions(threshold=np.nan) #numpy arrays will print the entire array now\n",
    "\n",
    "#create a .csv file of ids and image_matricies and save it to the data/preprocessed folder\n",
    "\n",
    "\n",
    "#current directory to process\n",
    "dir=\"../data/included/Test/\"\n",
    "\n",
    "BREED_LIST = \"../data/preprocessed_data/breed_list.csv\"\n",
    "\n",
    "\n",
    "#prepare the breed list dataframe\n",
    "labels = populate_breeds(BREED_LIST) #get the list of all dog breeds\n",
    "labels_np = np.array(labels).reshape(120,1) #labels list reshaped to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageDimensions(file_name, original_dir=\"../data/included/Train/\"):\n",
    "    file = original_dir + \"\" + file_name #store the file name and location  \n",
    "    image = Image.open(file)\n",
    "    width, height = image.size\n",
    "    return width, height\n",
    "\n",
    "def dimensionAnalysis(dir=\"../data/included/Test/\"):\n",
    "    data_files = os.listdir(dir) #get a list of all filenames from Train dir\n",
    "    \n",
    "    n = 0\n",
    "    x_total = 0\n",
    "    y_total = 0\n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "    \n",
    "    for file in data_files:\n",
    "        x = 0\n",
    "        y = 0\n",
    "        x,y = getImageDimensions(file)\n",
    "        n+=1\n",
    "        x_total+= x\n",
    "        y_total+= y        \n",
    "        \n",
    "        if(x>x_max):\n",
    "            x_max = x\n",
    "            print(file)\n",
    "            print(x)\n",
    "        if(y>y_max):\n",
    "            y_max = y\n",
    "        \n",
    "    x_avg = x_total/n\n",
    "    y_avg = y_total/n\n",
    "    \n",
    "    print(\"The avg x dimension is: \" + str(x_avg))\n",
    "    print(\"The avg y dimension is: \" + str(y_avg))\n",
    "    print(\"The Maximum width is: \" + str(x_max))\n",
    "    print(\"The Maximum height is: \" + str(y_max))\n",
    "    \n",
    "dimensionAnalysis(dir=\"../data/included/Train\")\n",
    "#solution:\n",
    "#  if width is under 500 add padding to make the image 500 x 500\n",
    "#  if height is under 500 add padding to make the image 500 x 500\n",
    "#  if either dimension > 500 scale down to get one dimension == to 500\n",
    "#     then add padding to get the other dimension == to 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert all images to grayscale vectors-- no longer used as NN will be using 500 x 500 x 3 images as input\n",
    "def normalize_image(file_name, original_dir=\"../data/included/Train/\",output_dir=\"../data/preprocessed_data/Train/\"):\n",
    "    file = original_dir + \"\" + file_name #store the file name and location  \n",
    "    image = Image.open(file)\n",
    "    \n",
    "    #scale the image to 500 x 500 x 3\n",
    "    \n",
    "    \n",
    "    #  if width is under 500 add padding to make the image 500 x 500\n",
    "    #  if height is under 500 add padding to make the image 500 x 500\n",
    "    #  if either dimension > 500 scale down to get one dimension == to 500\n",
    "    #     then add padding to get the other dimension == to 500\n",
    "    \n",
    "    width, height = image.size\n",
    "    \n",
    "    if(width > 500 or height > 500): #if width is greater than 500 or the height is greater than 500\n",
    "        if(width > height): #determine which side length is greater\n",
    "            image_ratio = 500/width #determine ratio of old image to new image\n",
    "        else:\n",
    "            image_ratio = 500/height\n",
    "             \n",
    "        width = int(width * image_ratio) #calculate new width\n",
    "        height = int(height * image_ratio) #calculate new height\n",
    "        image = image.resize((500, height), resample=1) #scale image to \n",
    "    \n",
    "        width, height = image.size #refresh the width and height to make sure everything is still accurate\n",
    "        delta_h = 500 - height #calculate the amount of height padding\n",
    "        delta_w = 500 - width #calculate the amount of width padding -- should be 0\n",
    "        padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
    "        image = ImageOps.expand(image, padding)\n",
    "    \n",
    "        #print(\"test1... \" + file_name) \n",
    "    \n",
    "    \n",
    "    width, height = image.size\n",
    "    #after neither size is greater than 500 or already scaled\n",
    "    if(width < 500 or height < 500): #if either dimension is less than 500 padding is added\n",
    "        #add padding to the height and width to change the image dimensions to 500 x 500 x 3\n",
    "        width, height = image.size #refresh the width and height to make sure everything is still accurate\n",
    "        delta_h = 500 - height #calculate the amount of height padding\n",
    "        delta_w = 500 - width #calculate the amount of width padding -- should be 0\n",
    "        padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
    "        image = ImageOps.expand(image, padding)\n",
    "    \n",
    "    \n",
    "    image_id = get_id_from_filename(file_name)\n",
    "    \n",
    "    width, height = image.size\n",
    "    if(width != 500 or height != 500):\n",
    "        print(\"something went wrong\")\n",
    "    \n",
    "    #save the image to the output_dir with the same id\n",
    "    image.save((output_dir + \"\" + image_id + \".png\"),format='PNG')    \n",
    "        \n",
    "        \n",
    "    return (file_name + \" ... saved\")\n",
    "\n",
    "\n",
    "#type(plt.imread(\"../data/included/Train/bd6a14ec09f86f3fef46f9433db8c445.jpg\"))\n",
    "#plt.imread(\"../data/included/Train/\" + image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process all of the Train files\n",
    "def pre_process(dir=\"../data/included/Train/\"):\n",
    "    data_files = os.listdir(dir) #get a list of all filenames from Train dir\n",
    "    \n",
    "    for file in data_files:\n",
    "        normalize_image(file)\n",
    "    \n",
    "    \n",
    "    return(True)\n",
    "pre_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load random image from training data\n",
    "img_loc = \"../data/preprocessed_data/Train/\" + get_random_id(dir=\"../data/included/Train/\") + \".png\"\n",
    "img = io.imread(img_loc, as_grey=False) #import image in greyscale\n",
    "\n",
    "#display the image\n",
    "io.imshow(img)\n",
    "io.show()\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert a directory of pre-processed images into a pandas dataframe for easy use with tensorflow\n",
    "def dataFrameBuilder(dir=\"../data/preprocessed_data/Train/\"):\n",
    "    df = pd.DataFrame(columns=['ID', 'Image Data', 'Breed'])\n",
    "    d = []\n",
    "    \n",
    "    data_files = os.listdir(dir) #get a list of all filenames from Train dir\n",
    "    counter = 0\n",
    "    segmenter = len(data_files)\n",
    "    \n",
    "    for file in data_files:\n",
    "        \n",
    "        file_id = get_id_from_filename(file)\n",
    "        data = get_imgMatrix_from_id(file_id)\n",
    "        breed_matrix = get_label_array_from_id(file_id, labels_np)\n",
    "        \n",
    "        d.append({'ID': file_id, 'Image Data': data, 'Breed': breed_matrix})\n",
    "       \n",
    "    \n",
    "        counter+=1\n",
    "        \n",
    "        if(counter > 10): #every 10 indexes in order to preserve ram\n",
    "            df_temp = pd.DataFrame(d, columns=['ID', 'Image Data', 'Breed']) #store list in a temp dataframe            \n",
    "            \n",
    "            df = pd.concat([df, df_temp]) #concatenate the temp df onto the end of df\n",
    "            \n",
    "            d = [] #clear the list \n",
    "            counter = 0 #restart the counter\n",
    "    \n",
    "    df_temp = pd.DataFrame(d) #initialize the DataFrame\n",
    "    df = pd.concat([df, df_temp])\n",
    "    df_temp = None\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = dataFrameBuilder()\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/ben/Documents/github/kaggle_dog_breed/data/preprocessed_data/train.csv\", del='\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = get_random_id()\n",
    "\n",
    "#file_id = get_id_from_filename(file)\n",
    "data = get_imgMatrix_from_id(file_id)\n",
    "breed_matrix = get_label_array_from_id(file_id, labels_np)\n",
    "\n",
    "\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie([square_cnt, long_horz_cnt, long_vert_cnt], labels=[\"square\", \"long horizontal\", \"long vertical\"])\n",
    "\n",
    "plt.show() \n",
    "\n",
    "list_of_widths = sorted(list_of_widths)\n",
    "list_of_heights = sorted(list_of_heights)\n",
    "\n",
    "#determine distribution of heights and widths of the images\n",
    "plt.plot(list_of_widths, mlb.normpdf(list_of_widths, np.mean(list_of_widths), np.std(list_of_widths)), '-o')\n",
    "plt.hist(list_of_widths, normed=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list_of_heights, mlb.normpdf(list_of_heights, np.mean(list_of_heights), np.std(list_of_heights)), '-o')\n",
    "plt.hist(list_of_heights, normed=True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Minimum image width: \", np.min(list_of_widths))\n",
    "print(\"Minimum image height: \", np.min(list_of_heights))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
