{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np #linear algebra\n",
    "import pandas as pd #data preprocessing\n",
    "import matplotlib.pyplot as plt #data visualization\n",
    "import h5py\n",
    "import PIL\n",
    "\n",
    "import utils.general_utils as util\n",
    "from utils.general_utils import populate_breeds, get_imgMatrix_from_id, get_breed_value_from_id, get_filename_from_id, get_id_from_filename\n",
    "#other built utilities\n",
    "\n",
    "from data_loader import dataFrameBuilder\n",
    "\n",
    "#using inception_v3 to classify dog breeds\n",
    "import tensorflow as tf #import tensroflow\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "image_size = 500 #all images are size image_size x image_size x 3\n",
    "batch_size = 10\n",
    "num_classes = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#prepare csv files\n",
    "train = pd.read_csv(\"../data/included/labels.csv\")\n",
    "test = pd.read_csv(\"../data/included/test_id.csv\")\n",
    "BREED_LIST = \"../data/preprocessed_data/breed_list.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the breed list dataframe\n",
    "labels = populate_breeds(BREED_LIST) #get the list of all dog breeds\n",
    "labels_np = np.array(labels).reshape(120,1) #labels list reshaped to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = tf.placeholder(tf.float32, shape=[None, 500,500, 3], name='input_data')\n",
    "\n",
    "x = tf.keras.layers.Input(shape=(500,500,3), batch_size=batch_size,name='input_data',dtype='float32')\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None, 120,1], name='correct_labels')\n",
    "#x=tf.placeholder(tf.float32, shape=[500,500,3],name='input_data')\n",
    "\n",
    "y_pred = tf.placeholder(tf.float32, shape=[None,120,1], name='predicted_labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(index=0, data_amnt = 1):\n",
    "    input_img_data = dataFrameBuilder(data_amount=data_amnt,\n",
    "                                      start_index=index)\n",
    "    #df.shuffle().repeat().batch(batch_size)\n",
    "    #print(df.sample(1))\n",
    "    #input_img_data = df.as_matrix(columns=['Image Data'])\n",
    "    #input_img_data.reshape([500,500,3])\n",
    "    input_img_data = np.asarray(input_img_data)\n",
    "    \n",
    "    return input_img_data\n",
    "\n",
    "def train_output_fn(index=0,data_amnt = 1):\n",
    "    output_breed_data = dataFrameBuilder(data_amount=data_amnt,\n",
    "                                         start_index=index,\n",
    "                                         ret_input=False,\n",
    "                                         ret_output=True)\n",
    "    #return df.as_matrix(columns=['Breed'])\n",
    "    output_breed_data = np.asarray(output_breed_data)\n",
    "    return output_breed_data\n",
    "\n",
    "'''\n",
    "batch_size\n",
    "    the number of samples returned\n",
    "\n",
    "features\n",
    "    either 'train' to use training data\n",
    "    or 'test' to return testing data\n",
    "'''\n",
    "def generator(batch_size, features = train):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features = np.zeros((batch_size, 500, 500, 3))\n",
    "    batch_labels = np.zeros((batch_size,120))\n",
    "    while True:\n",
    "        for i in range(batch_size):     \n",
    "            # choose random index in features\n",
    "            index= random.choice([len(features),1])\n",
    "            batch_features[i] = train_input_fn(index=index, data_amnt=1)\n",
    "            batch_labels[i] = train_output_fn(index=index, data_amnt=1)\n",
    "        yield batch_features, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3 = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                input_tensor=x,\n",
    "                                                classes=120)\n",
    "\n",
    "#set imagedata to channels_last for best performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "output_layer = inception_v3.output\n",
    "output_layer = tf.keras.layers.GlobalAveragePooling2D()(output_layer)\n",
    "# let's add a fully-connected layer\n",
    "output_layer = tf.keras.layers.Dense(1024, activation='relu')(output_layer)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = tf.keras.layers.Dense(120, activation='softmax')(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = tf.keras.Model(inputs=inception_v3.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_data\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n",
      "311 global_average_pooling2d_1\n",
      "312 dense_1\n",
      "313 dense_2\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 91s 9s/step - loss: 0.9618\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 9s 890ms/step - loss: 0.0231\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.0123\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.0083\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0063\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0050\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0042\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.0036\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0031\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0028\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0025\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.0023\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0021\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0019\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0018\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0016\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0015\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0014\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0013\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.0013\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0012\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.0011\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0011\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0010\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 9.9849e-04\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 9.5660e-04\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 9.1794e-04\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 8.8228e-04\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 8.4914e-04\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 8.1833e-04\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 7.8963e-04\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 7.6280e-04\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 7.3767e-04\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 7.1416e-04\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 6.9199e-04\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 6.7114e-04\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 6.5149e-04\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 6.3292e-04\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 6.1538e-04\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 5.9872e-04\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 5.8291e-04\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 5.6792e-04\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 5.5367e-04\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 5.4007e-04\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 5.2709e-04\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 5.1473e-04\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 5.0293e-04\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 4.9161e-04\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 4.8079e-04\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 4.7038e-04\n",
      "10/10 [==============================] - 19s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.244642734527588"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "#with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as ss:\n",
    "                             \n",
    "x = tf.keras.layers.Input(shape=(500,500,3), batch_size=batch_size,name='input_data',dtype='float32')\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None, 120,1], name='correct_labels')\n",
    "#x=tf.placeholder(tf.float32, shape=[500,500,3],name='input_data')\n",
    "\n",
    "y_pred = tf.placeholder(tf.float32, shape=[None,120,1], name='predicted_labels')\n",
    "\n",
    "\n",
    "inception_v3 = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                 weights='imagenet',\n",
    "                                                input_tensor=x,\n",
    "                                                classes=120)\n",
    "\n",
    "#steps for adding a new output layer\n",
    "output_layer = inception_v3.output\n",
    "output_layer = tf.keras.layers.GlobalAveragePooling2D()(output_layer) #replace the current global avg pool 2d\n",
    "output_layer = tf.keras.layers.Dense(1024, activation='relu')(output_layer) \n",
    "predictions = tf.keras.layers.Dense(120, activation='softmax')(output_layer) #120 classes in the new model\n",
    "\n",
    "model = tf.keras.Model(inputs=inception_v3.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                    optimizer='sgd')\n",
    "\n",
    "#img_data = train_input_fn(data_amnt=batch_size)\n",
    "#breed_data = train_output_fn(data_amnt=batch_size)\n",
    "\n",
    "#model.fit(x=img_data, y=breed_data, batch_size=batch_size)\n",
    "\n",
    "#inception_v3.fit_generator(generator)\n",
    "#model.fit_generator(generator(features, labels, batch_size), samples_per_epoch=50, nb_epoch=10)\n",
    "#print(img_data[0])\n",
    "model.fit_generator(generator(batch_size), steps_per_epoch=10, epochs=50)\n",
    "\n",
    "\n",
    "index = 11\n",
    "\n",
    "img_data = train_input_fn(index=index, data_amnt=batch_size)\n",
    "breed_data = train_output_fn(index=index, data_amnt=batch_size)\n",
    "\n",
    "#sample_weight=np.transpose(np.ones(120, dtype='float32'))\n",
    "#model.evaluate(x=img_data,y=breed_data,batch_size=batch_size, sample_weight=sample_weight) \n",
    "model.evaluate(x=img_data, y=breed_data,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   000621fb3cbb32d8935728e48679680e.png\n",
      "1   00102ee9d8eb90812350685311fe5890.png\n",
      "2   0012a730dfa437f5f3613fb75efcd4ce.png\n",
      "3   001510bc8570bbeee98c8d80c8a95ec1.png\n",
      "4   001a5f3114548acdefa3d4da05474c2e.png\n",
      "5   00225dcd3e4d2410dd53239f95c0352f.png\n",
      "6   002c2a3117c2193b4d26400ce431eebd.png\n",
      "7   002c58d413a521ae8d1a5daeb35fc803.png\n",
      "8   002f80396f1e3db687c5932d7978b196.png\n",
      "9   0036c6bcec6031be9e62a257b1c3c442.png\n"
     ]
    }
   ],
   "source": [
    "def test_input_fn(index=0, data_amnt = 1):\n",
    "    input_img_data = dataFrameBuilder(data_amount=data_amnt,\n",
    "                                      start_index=index,\n",
    "                                     dir=\"../data/preprocessed_data/Test/\")\n",
    "\n",
    "    input_img_data = np.asarray(input_img_data)\n",
    "    return input_img_data\n",
    "\n",
    "\n",
    "data_files = os.listdir(\"../data/preprocessed_data/Test/\") #get a list of all filenames from Train dir\n",
    "file_index = 0\n",
    "\n",
    "'''\n",
    "temp_id = get_id_from_filename(data_files[])\n",
    "temp_file_data = test_input_fn(index=0, data_amnt=10)\n",
    "temp_file_prediction = model.predict(x=file_data, batch_size = 10)\n",
    "'''\n",
    "\n",
    "file_ids = []\n",
    "file_prediction = []\n",
    "\n",
    "for file in data_files:   \n",
    "    print(file_index, ' ', file)\n",
    "    #append id to a list\n",
    "    #once the 10th id is reached, append all predictions to a list\n",
    "    #combine\n",
    "    \n",
    "    file_ids.append(get_id_from_filename(file)) #append the current id to the list of ids\n",
    "    if(file_index%10 == 0): #every 10 indexes        \n",
    "        file_data= test_input_fn(index=file_index, data_amnt=10)    \n",
    "        predictions = model.predict(x=file_data, batch_size = 10)\n",
    "        for prediction in predictions:\n",
    "            file_prediction.append(prediction)\n",
    "\n",
    "    if(file_index>= 9):\n",
    "        break\n",
    "    \n",
    "    file_index += 1\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000621fb3cbb32d8935728e48679680e', '00102ee9d8eb90812350685311fe5890', '0012a730dfa437f5f3613fb75efcd4ce', '001510bc8570bbeee98c8d80c8a95ec1', '001a5f3114548acdefa3d4da05474c2e', '00225dcd3e4d2410dd53239f95c0352f', '002c2a3117c2193b4d26400ce431eebd', '002c58d413a521ae8d1a5daeb35fc803', '002f80396f1e3db687c5932d7978b196', '0036c6bcec6031be9e62a257b1c3c442']\n",
      "\n",
      "\n",
      "0.0003945509\n"
     ]
    }
   ],
   "source": [
    "print(file_ids)\n",
    "print(\"\\n\")\n",
    "print(file_prediction[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'affenpinscher', 'afghan_hound', 'african_hunting_dog', 'airedale', 'american_staffordshire_terrier', 'appenzeller', 'australian_terrier', 'basenji', 'basset', 'beagle', 'bedlington_terrier', 'bernese_mountain_dog', 'black-and-tan_coonhound', 'blenheim_spaniel', 'bloodhound', 'bluetick', 'border_collie', 'border_terrier', 'borzoi', 'boston_bull', 'bouvier_des_flandres', 'boxer', 'brabancon_griffon', 'briard', 'brittany_spaniel', 'bull_mastiff', 'cairn', 'cardigan', 'chesapeake_bay_retriever', 'chihuahua', 'chow', 'clumber', 'cocker_spaniel', 'collie', 'curly-coated_retriever', 'dandie_dinmont', 'dhole', 'dingo', 'doberman', 'english_foxhound', 'english_setter', 'english_springer', 'entlebucher', 'eskimo_dog', 'flat-coated_retriever', 'french_bulldog', 'german_shepherd', 'german_short-haired_pointer', 'giant_schnauzer', 'golden_retriever', 'gordon_setter', 'great_dane', 'great_pyrenees', 'greater_swiss_mountain_dog', 'groenendael', 'ibizan_hound', 'irish_setter', 'irish_terrier', 'irish_water_spaniel', 'irish_wolfhound', 'italian_greyhound', 'japanese_spaniel', 'keeshond', 'kelpie', 'kerry_blue_terrier', 'komondor', 'kuvasz', 'labrador_retriever', 'lakeland_terrier', 'leonberg', 'lhasa', 'malamute', 'malinois', 'maltese_dog', 'mexican_hairless', 'miniature_pinscher', 'miniature_poodle', 'miniature_schnauzer', 'newfoundland', 'norfolk_terrier', 'norwegian_elkhound', 'norwich_terrier', 'old_english_sheepdog', 'otterhound', 'papillon', 'pekinese', 'pembroke', 'pomeranian', 'pug', 'redbone', 'rhodesian_ridgeback', 'rottweiler', 'saint_bernard', 'saluki', 'samoyed', 'schipperke', 'scotch_terrier', 'scottish_deerhound', 'sealyham_terrier', 'shetland_sheepdog', 'shih-tzu', 'siberian_husky', 'silky_terrier', 'soft-coated_wheaten_terrier', 'staffordshire_bullterrier', 'standard_poodle', 'standard_schnauzer', 'sussex_spaniel', 'tibetan_mastiff', 'tibetan_terrier', 'toy_poodle', 'toy_terrier', 'vizsla', 'walker_hound', 'weimaraner', 'welsh_springer_spaniel', 'west_highland_white_terrier', 'whippet', 'wire-haired_fox_terrier', 'yorkshire_terrier']\n",
      "(2, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0036c6bcec6031be9e62a257b1c3c442</td>\n",
       "      <td>0.0007825534</td>\n",
       "      <td>0.0003945509</td>\n",
       "      <td>0.00015902561</td>\n",
       "      <td>0.0007761166</td>\n",
       "      <td>0.0007525283</td>\n",
       "      <td>0.00047848417</td>\n",
       "      <td>0.0007207573</td>\n",
       "      <td>0.0007219867</td>\n",
       "      <td>0.000770615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0002519139</td>\n",
       "      <td>0.00047761246</td>\n",
       "      <td>0.0010034071</td>\n",
       "      <td>0.00040659515</td>\n",
       "      <td>0.0004355653</td>\n",
       "      <td>0.00046328665</td>\n",
       "      <td>0.0006567028</td>\n",
       "      <td>0.00039705768</td>\n",
       "      <td>0.00082491693</td>\n",
       "      <td>0.0007428286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id affenpinscher  afghan_hound  \\\n",
       "0  0036c6bcec6031be9e62a257b1c3c442  0.0007825534  0.0003945509   \n",
       "\n",
       "  african_hunting_dog      airedale american_staffordshire_terrier  \\\n",
       "0       0.00015902561  0.0007761166                   0.0007525283   \n",
       "\n",
       "     appenzeller australian_terrier       basenji       basset  \\\n",
       "0  0.00047848417       0.0007207573  0.0007219867  0.000770615   \n",
       "\n",
       "         ...           toy_poodle    toy_terrier        vizsla   walker_hound  \\\n",
       "0        ...         0.0002519139  0.00047761246  0.0010034071  0.00040659515   \n",
       "\n",
       "     weimaraner welsh_springer_spaniel west_highland_white_terrier  \\\n",
       "0  0.0004355653          0.00046328665                0.0006567028   \n",
       "\n",
       "         whippet wire-haired_fox_terrier yorkshire_terrier  \n",
       "0  0.00039705768           0.00082491693      0.0007428286  \n",
       "\n",
       "[1 rows x 121 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = ['id'] #set up the dataframe column labels\n",
    "\n",
    "for label in labels_np: #append each breed as a new column\n",
    "    df_labels.append(label[0])\n",
    "\n",
    "df_labels_np = np.asarray(list(df_labels)).T\n",
    "\n",
    "    \n",
    "predictions_data = []\n",
    "\n",
    "for id in file_ids:\n",
    "    i = 0 #index in current row of data\n",
    "    single_prediction = []\n",
    "    single_prediction.append(id) \n",
    "    for column in file_prediction[i]: #access each individual prediction in a single id's row\n",
    "        single_prediction.append(column) #add a single breed prediction to the data\n",
    "    \n",
    "        \n",
    "    single_prediction = np.asarray(single_prediction).reshape((1,121))\n",
    "    #print(single_prediction.shape)\n",
    "    if(i == 0):\n",
    "        predictions_data = single_prediction[0]\n",
    "    \n",
    "    #predictions_data = np.concatenate(predictions_data, single_prediction[0])\n",
    "    #print(i, ' ', predictions_data[i])\n",
    "    i += 1 #iterate to the next id\n",
    "\n",
    "\n",
    "#predictions_data = np.asarray(predictions_data)\n",
    "#predictions_data.shape()\n",
    "output = np.vstack((predictions_data, predictions_data))\n",
    "print(output.shape)\n",
    "predictions_df = pd.DataFrame(output, columns=df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
