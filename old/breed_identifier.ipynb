{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "#import libraries\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Sets\n",
    "BREED_TRAINING = \"data/Train\"\n",
    "BREED_TRAINING_LABELS = \"data/labels.csv\"\n",
    "\n",
    "BREED_TEST = \"data/Test\"\n",
    "#testing_data = open(\"data/sample_submission.csv\")\n",
    "\n",
    "FEATURE_KEYS = ['image_matrix','breed']\n",
    "#data type of input matrix is np.ndarray()\n",
    "\n",
    "MODEL_PATH = \"Models/\"\n",
    "\n",
    "#all data should already be downloaded\n",
    "\n",
    "#parameters\n",
    "train = True #start training NN\n",
    "test = False #test NN\n",
    "num_breeds = 120\n",
    "num_steps = 1\n",
    "\n",
    "\n",
    "image_matrix = tf.placeholder(tf.int8, shape =[250,250]) #shape = [None] ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get pixel data from image stored in folder\n",
    "# example usage: \n",
    "#get_imgMatrix_from_id(data[h0][5])\n",
    "def get_imgMatrix_from_id(image_id, image_dir=\"data/Train\"):\n",
    "    image_loc = image_dir + \"/\" + image_id + \".jpg\"\n",
    "    \n",
    "    #return plt.imread(image_loc)\n",
    "    image = tf.image.decode_jpeg(3) #Decode a JPEG-encoded image to a uint8 tensor\n",
    "    resized_img = tf.image.resize_images(image,(250,250)) #resize all images to 250x250\n",
    "    return resized_img\n",
    "\n",
    "#new get_imgMatrix\n",
    "#tf.image.deocde_jpeg \n",
    "#returns a unint8 tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dict = { } #a dictionary in which the keys are feature names and the values are \n",
    "#Tensors (or SparseTensors) containing the corresponding feature data\n",
    "\n",
    "headers = [] #arrays that holds all headers\n",
    "labels = {\"affenpinscher\",\"afghan_hound\",\"african_hunting_dog\",\"airedale\",\"american_staffordshire_terrier\",\"appenzeller\",\"australian_terrier\",\"basenji\",\"basset\",\"beagle\",\"bedlington_terrier\",\"bernese_mountain_dog\",\"black-and-tan_coonhound\",\"blenheim_spaniel\",\"bloodhound\",\"bluetick\",\"border_collie\",\"border_terrier\",\"borzoi\",\"boston_bull\",\"bouvier_des_flandres\",\"boxer\",\"brabancon_griffon\",\"briard\",\"brittany_spaniel\",\"bull_mastiff\",\"cairn\",\"cardigan\",\"chesapeake_bay_retriever\",\"chihuahua\",\"chow\",\"clumber\",\"cocker_spaniel\",\"collie\",\"curly-coated_retriever\",\"dandie_dinmont\",\"dhole\",\"dingo\",\"doberman\",\"english_foxhound\",\"english_setter\",\"english_springer\",\"entlebucher\",\"eskimo_dog\",\"flat-coated_retriever\",\"french_bulldog\",\"german_shepherd\",\"german_short-haired_pointer\",\"giant_schnauzer\",\"golden_retriever\",\"gordon_setter\",\"great_dane\",\"great_pyrenees\",\"greater_swiss_mountain_dog\",\"groenendael\",\"ibizan_hound\",\"irish_setter\",\"irish_terrier\",\"irish_water_spaniel\",\"irish_wolfhound\",\"italian_greyhound\",\"japanese_spaniel\",\"keeshond\",\"kelpie\",\"kerry_blue_terrier\",\"komondor\",\"kuvasz\",\"labrador_retriever\",\"lakeland_terrier\",\"leonberg\",\"lhasa\",\"malamute\",\"malinois\",\"maltese_dog\",\"mexican_hairless\",\"miniature_pinscher\",\"miniature_poodle\",\"miniature_schnauzer\",\"newfoundland\",\"norfolk_terrier\",\"norwegian_elkhound\",\"norwich_terrier\",\"old_english_sheepdog\",\"otterhound\",\"papillon\",\"pekinese\",\"pembroke\",\"pomeranian\",\"pug\",\"redbone\",\"rhodesian_ridgeback\",\"rottweiler\",\"saint_bernard\",\"saluki\",\"samoyed\",\"schipperke\",\"scotch_terrier\",\"scottish_deerhound\",\"sealyham_terrier\",\"shetland_sheepdog\",\"shih-tzu\",\"siberian_husky\",\"silky_terrier\",\"soft-coated_wheaten_terrier\",\"staffordshire_bullterrier\",\"standard_poodle\",\"standard_schnauzer\",\"sussex_spaniel\",\"tibetan_mastiff\",\"tibetan_terrier\",\"toy_poodle\",\"toy_terrier\",\"vizsla\",\"walker_hound\",\"weimaraner\",\"welsh_springer_spaniel\",\"west_highland_white_terrier\",\"whippet\",\"wire-haired_fox_terrier\",\"yorkshire_terrier\"}\n",
    "#labels of what we are trying to predict\n",
    "\n",
    "#input_fn doesn't need to handle ids, just handle image inputs\n",
    "def input_fn(file_name, num_data, batch_size, is_training):\n",
    "  \"\"\"Creates an input_fn required by Estimator train/evaluate.\"\"\"\n",
    "    \n",
    "    #Convert the inputs to a Dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    #preprocess your data here\n",
    "    f = open(file_name, 'r',) #open csv file\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    headers = next(reader) #retrieve header names\n",
    "    \n",
    "    h0 = headers[0] #id\n",
    "    h1 = headers[1] #breed\n",
    "    h2 = \"image\" #uint8\n",
    "    \n",
    "    feature_dict[h0] = [] #list of ids\n",
    "    feature_dict[h1] = [] #list of breeds\n",
    "    feature_dict[h2] = [] #list of image arrays\n",
    "    #data[headers[0]] = []\n",
    "    # ...\n",
    "        \n",
    "    \n",
    "    for row in reader: #loop through reader\n",
    "        feature_dict[h0].append(row[0]) #appends id\n",
    "        feature_dict[h1].append(row[1]) #appends breed\n",
    "        feature_dict[h2].append(get_imgMatrix_from_id(row[0])) #appends image matrix based on id\n",
    "        \n",
    "    \n",
    "    #...a tensor containing the labels\n",
    "    #labels = the values your models aims to predict\n",
    "       \n",
    "    \n",
    "    def _input_fn():\n",
    "        \"\"\"the input_fn\"\"\"\n",
    "        dataset = tf.data.Dataset([filename])\n",
    "        dataset = dataset.skip(1)\n",
    "        dataset = dataset.map(_parse_csv)\n",
    "        \n",
    "        return features, labels\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the input function -- see tensorflow documentation\n",
    "#def input_fn ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a 3 layer neural network\n",
    "def neural_net(x_dict): #pass in a dictionary of image matricies NOT IDs\n",
    "    \n",
    "    #3 layers \n",
    "    #TODO: Add more layers\n",
    "    l0 = x_dict #the input layer\n",
    "    l1 = tf.layers.dense(l0,256) #layer one, uses sigmoid function to calculate weights\n",
    "    l2 = tf.layers.dense(l1, num_breeds) #the output layer\n",
    "    \n",
    "    return l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf estimator model function\n",
    "def model_fn(features, labels, mode, params):    \n",
    "    #this function is where the most machine learning knowledge comes into play\n",
    "    \n",
    "    #build the neural network\n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    #Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=3)\n",
    "    print(\"pred classes: \" + pred_classes)\n",
    "        \n",
    "    #compute loss and optimizer - taken from Tensorflow custom_estimator doc\n",
    "    loss_op = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits) #TODO:use signmoid instead\n",
    "    train_op = optimizer.minimize(loss_op, )\n",
    "            \n",
    "\n",
    "    estimator = DNNEstimator(\n",
    "        head=tf.contrib.estimator.multi_label_head(n_classes=3),\n",
    "        feature_columns=[sparse_feature_a_emb, sparse_feature_b_emb],\n",
    "        hidden_units=[1024, 512, 256])\n",
    "    \n",
    "    #specifies the required ops for the estimator and returns\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, #mode is not required, TODO:maybe createa a param for mode and access it here\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op)    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.0 define the feature columns\n",
    "#exampple: image_ft = tf.feature_column.numeric_column('population')\n",
    "#image_ft = tf.placeholder(tf.int8, shape =[250,250]) #shape = [None] ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Estimator' has no attribute 'LinearClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-509b848265f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#build the estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#use tensorflow estimator -- see tensorflow documentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = tf.estimator.Estimator.LinearClassifier(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_ft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Estimator' has no attribute 'LinearClassifier'"
     ]
    }
   ],
   "source": [
    "#build the estimator\n",
    "#use tensorflow estimator -- see tensorflow documentation\n",
    "#model = tf.estimator.Estimator.LinearClassifier(\n",
    "#    feature_columns=[image_ft],\n",
    "#    )\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b3097259dd79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_fn' is not defined"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model.train(input_fn=input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1b5bb63c6472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#test the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mds_predict_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_imgMatrix_from_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0a0b97441050bba8e733506de4655ea1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data/Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_predict_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#test the network\n",
    "\n",
    "ds_predict_tf = model.predict(get_imgMatrix_from_id(\"0a0b97441050bba8e733506de4655ea1\",'data/Test'))\n",
    "for i in ds_predict_tf:\n",
    "    print(i)\n",
    "                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "test = get_imgMatrix_from_id(\"0a0b97441050bba8e733506de4655ea1\", image_dir=\"data/Test\")\n",
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gameAI)",
   "language": "python",
   "name": "gameai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
